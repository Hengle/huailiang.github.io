<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Python扒取网络图片</title>
  <meta name="description"
    content="  就像一个黑客，随意扒取别人的资源为己用，想想就知道是一件多么酷的事儿，好像全世界的图片都是我的一样。">

  <link rel="shortcut icon" href="img/favicon.ico">
  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="https://huailiang.github.io/blog/2018/urlib/">
  <link rel="alternate" type="application/rss+xml" title="Huailiang Blog"
    href="https://huailiang.github.io/feed.xml" />
</head>
  <body>
    <main>
      <header class="site-header">
  <div class="container">
    <h1><a href="/">Hom<span>e</span></a></h1>

    <button type="button" class="sliding-panel-button">
      <span></span>
      <span></span>
      <span></span>
    </button>

    <nav class="navbar sliding-panel-content">
      <ul>
        
        <li><a href="/about" title="About">About</a>
        </li>
        
        <li><a href="/blog" title="Blog">Blog</a>
        </li>
        
        <!-- <li><a href="https://github.com/huailiang/archive/master.zip" title="Download">Download</a></li> -->
        <li><a href="/feed.xml" target="_blank"><i class="icon icon-feed"></i></a></li>
      </ul>
    </nav>
  </div>
</header>

<div class="sliding-panel-fade-screen"></div>

      <div class="container">
        <article role="article" class="post">

  <div class="card">
    <header class="post-header">
      <h1 class="post-title">Python扒取网络图片</h1>
      <p class="post-meta">Mar 11, 2018 •
        Huailiang</p>
    </header>

    <div class="post-content">
      <blockquote>
  <p>就像一个黑客，随意扒取别人的资源为己用，想想就知道是一件多么酷的事儿，好像全世界的图片都是我的一样。</p>
</blockquote>

<p>首先安装 BeautifulSoup。</p>

<p>beautifulsoup就是一个非常强大的工具，爬虫利器。</p>

<p>beautifulSoup “美味的汤，绿色的浓汤”</p>

<p>一个灵活又方便的网页解析库，处理高效，支持多种解析器。</p>

<p>利用它就不用编写正则表达式也能方便的实现网页信息的抓取。</p>

<p>Beautiful Soup支持Python标准库中的HTML解析器,还支持一些第三方的解析器，如果我们不安装它，则 Python 会使用 Python默认的解析器，lxml 解析器更加强大，速度更快，推荐安装。</p>

<p><img src="/img/in-post/post-tf/ft24.png" alt="" /></p>

<h3 id="基本使用">基本使用</h3>
<p>标签选择器</p>

<p>在快速使用中我们添加如下代码：</p>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">print</span><span class="p">(</span><span class="n">soup</span><span class="o">.</span><span class="n">title</span><span class="p">)</span>
  <span class="k">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">soup</span><span class="o">.</span><span class="n">title</span><span class="p">))</span>
  <span class="k">print</span><span class="p">(</span><span class="n">soup</span><span class="o">.</span><span class="n">head</span><span class="p">)</span>
  <span class="k">print</span><span class="p">(</span><span class="n">soup</span><span class="o">.</span><span class="n">p</span><span class="p">)</span></code></pre></div>

<p>通过这种soup.标签名 我们就可以获得这个标签的内容<br />
  这里有个问题需要注意，通过这种方式获取标签，如果文档中有多个这样的标签，返回的结果是第一个标签的内容，如上面我们通过soup.p获取p标签，而文档中有多个p标签，但是只返回了第一个p标签内容</p>

<ul>
  <li>
    <p>获取名称</p>

    <p>当我们通过soup.title.name的时候就可以获得该title标签的名称，即title</p>
  </li>
  <li>
    <p>获取属性</p>
  </li>
</ul>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">print</span><span class="p">(</span><span class="n">soup</span><span class="o">.</span><span class="n">p</span><span class="o">.</span><span class="n">attrs</span><span class="p">[</span><span class="s">&#39;name&#39;</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="n">soup</span><span class="o">.</span><span class="n">p</span><span class="p">[</span><span class="s">&#39;name&#39;</span><span class="p">])</span></code></pre></div>

<p>上面两种方式都可以获取p标签的name属性值</p>

<ul>
  <li>获取内容</li>
</ul>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">print</span><span class="p">(</span><span class="n">soup</span><span class="o">.</span><span class="n">p</span><span class="o">.</span><span class="n">string</span><span class="p">)</span></code></pre></div>

<p>结果就可以获取第一个p标签的内容：<br />
  The Dormouse’s story</p>

<ul>
  <li>
    <p>嵌套选择</p>

    <p>我们直接可以通过下面嵌套的方式获取</p>
  </li>
</ul>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">print</span><span class="p">(</span><span class="n">soup</span><span class="o">.</span><span class="n">head</span><span class="o">.</span><span class="n">title</span><span class="o">.</span><span class="n">string</span><span class="p">)</span></code></pre></div>

<p>下面代码就是展示了利用 BeautifulSoup 扒取《国家地理》里的精美图片。我们可以设置最大的链接页面 max=5. 所有扒取的图片都存在跟nationalgeographic文件夹下。</p>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="c"># coding=utf-8</span>

<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">shutil</span>
<span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>
<span class="kn">from</span> <span class="nn">urllib</span> <span class="kn">import</span> <span class="n">urlretrieve</span>

<span class="nb">max</span><span class="o">=</span><span class="mi">5</span>
<span class="n">dest</span> <span class="o">=</span> <span class="s">&quot;./nationalgeographic/&quot;</span>
<span class="n">URL</span> <span class="o">=</span> <span class="s">&quot;http://www.nationalgeographic.com.cn/animals/&quot;</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">扒取之前，先清理干净本地目录</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="k">def</span> <span class="nf">clear</span><span class="p">():</span>
	<span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">dest</span><span class="p">):</span>
		<span class="n">shutil</span><span class="o">.</span><span class="n">rmtree</span><span class="p">(</span><span class="n">dest</span><span class="p">)</span>
	<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">dest</span><span class="p">)</span>


<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">扒取下载图片</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="k">def</span> <span class="nf">download</span><span class="p">(</span><span class="n">addr</span><span class="p">):</span>
	<span class="c"># 用global关键字来进行说明该变量是全局变量</span>
	<span class="k">global</span> <span class="nb">max</span>

	<span class="n">html</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">addr</span><span class="p">)</span><span class="o">.</span><span class="n">text</span>
	<span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">html</span><span class="p">,</span><span class="s">&quot;lxml&quot;</span><span class="p">)</span>
	<span class="k">print</span> <span class="n">soup</span><span class="o">.</span><span class="n">title</span>
	<span class="n">imgs</span><span class="o">=</span><span class="n">soup</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s">&#39;img&#39;</span><span class="p">)</span>
	<span class="k">for</span> <span class="n">img</span> <span class="ow">in</span> <span class="n">imgs</span><span class="p">:</span>
		<span class="n">url</span><span class="o">=</span><span class="n">img</span><span class="p">[</span><span class="s">&#39;src&#39;</span><span class="p">]</span>
		<span class="nb">file</span><span class="o">=</span><span class="n">url</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">&#39;/&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
		<span class="k">if</span> <span class="n">url</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s">&quot;http&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">url</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s">&quot;jpg&quot;</span><span class="p">):</span>
		<span class="c"># urlretrieve(url,dest+file)</span>
			<span class="k">print</span> <span class="n">url</span>
			<span class="n">r</span><span class="o">=</span><span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span><span class="n">stream</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
			<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">dest</span><span class="o">+</span><span class="nb">file</span><span class="p">,</span><span class="s">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
				<span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">r</span><span class="o">.</span><span class="n">iter_content</span><span class="p">(</span><span class="n">chunk_size</span><span class="o">=</span><span class="mi">128</span><span class="p">):</span>
					<span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>
	<span class="n">links</span><span class="o">=</span><span class="n">soup</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s">&#39;a&#39;</span><span class="p">)</span>
	<span class="k">for</span> <span class="n">link</span> <span class="ow">in</span> <span class="n">links</span><span class="p">:</span>
	 	<span class="n">url</span><span class="o">=</span><span class="n">link</span><span class="p">[</span><span class="s">&#39;href&#39;</span><span class="p">]</span>
	 	<span class="c"># print url</span>
	 	<span class="k">if</span> <span class="nb">max</span> <span class="o">&gt;</span><span class="mi">0</span> <span class="ow">and</span> <span class="n">url</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s">&quot;http&quot;</span><span class="p">):</span>
 			<span class="n">download</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
	 		<span class="nb">max</span><span class="o">=</span><span class="nb">max</span><span class="o">-</span><span class="mi">1</span>

<span class="k">if</span> <span class="n">__name__</span><span class="o">==</span><span class="s">&quot;__main__&quot;</span><span class="p">:</span>
	<span class="n">clear</span><span class="p">()</span>
	<span class="n">download</span><span class="p">(</span><span class="n">URL</span><span class="p">)</span></code></pre></div>

<p>当我们使用urlretrieve下载图片的时候，发现有的图片下载不下来，使用requests.get(url,stream=True)可以比较完整的下载图片。</p>

<p><img src="/img/in-post/post-tf/tf23.png" alt="" /></p>

<p>我们也可以多进程下载，这样可以加快下载速度。</p>

<p>代码实现类似这样：</p>

<div class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">multiprocessing</span> <span class="kn">as</span> <span class="nn">mp</span>
<span class="kn">import</span> <span class="nn">threading</span> <span class="kn">as</span> <span class="nn">td</span>

<span class="k">if</span> <span class="n">__name__</span><span class="o">==</span><span class="s">&quot;__main__&quot;</span><span class="p">:</span>
	<span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">categorie</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">categories</span><span class="p">):</span>
		<span class="n">clear</span><span class="p">(</span><span class="n">categorie</span><span class="p">)</span>
		<span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">categorie</span><span class="p">)</span>
		<span class="c">#使用多进程</span>
		<span class="n">p</span><span class="o">=</span><span class="n">mp</span><span class="o">.</span><span class="n">Process</span><span class="p">(</span><span class="n">target</span><span class="o">=</span><span class="n">download</span><span class="p">,</span><span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">categorie</span><span class="p">,))</span>
		<span class="n">p</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
    <span class="c"># p.join()</span></code></pre></div>

<p>在使用多进程的时候，在 for 循环中调用 jion 的时候，发现并不能触发多进程，实际上只有一个进程，另一个进程可能在等待。</p>

<p>还有就是 args是一定是（）元组，当参数只有一个时候，记得加一个逗号。否则会包参数不对的 error.</p>

<p>在 Unix 平台山，当某个进程终结之后，该进程需要被父进程调用 wait,否则进程成为僵尸进程（Zombie). 所以有必要对每个 Process对象调用 join() 函数。</p>

<p>对于多进程的使用，我们强烈建议使用进程池，详情请参考<a href="http://blog.csdn.net/seetheworld518/article/details/49639651">这篇文章</a></p>


    </div>

  </div>

</article>
      </div>

      <footer class="site-footer">
  <div class="container">
    <ul class="social">
  <li><a href="https://github.com/huailiang" target="_blank"><i class="icon icon-github"></i></a></li>
  <li><a href="https://twitter.com/penghuailiang" target="_blank"><i class="icon icon-twitter"></i></a></li>
  <li><a href="https://www.facebook.com/profile.php?id=100004290725320" target="_blank"><i class="icon icon-facebook"></i></a></li>
  <li><a href="https://www.linkedin.com/in/penghuailiang/" target="_blank"><i class="icon icon-linkedin"></i></a></li>
</ul>
    <p class="txt-medium-gray">
      <small>&copy;2019 All rights reserved. Made with <a href="https://huailiang.github.io/"
          target="_blank">Huailiang</a> and ♥</small>
    </p>
  </div>
</footer>

      <a href="https://github.com/huailiang" target="_blank" class="github-corner"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#337ab7; color:#fff; position: absolute; top: 0; border: 0; right: 0;"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

      <script src="//code.jquery.com/jquery-1.11.3.min.js"></script>
      <script>
      $(document).ready(function() {
        $('.sliding-panel-button,.sliding-panel-fade-screen,.sliding-panel-close').on('click touchstart',function (e) {
          $('.sliding-panel-content,.sliding-panel-fade-screen').toggleClass('is-visible');
          e.preventDefault();
        });
      });
      </script>
    </main>
  </body>
</html>
