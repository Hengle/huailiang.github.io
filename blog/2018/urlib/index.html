<!DOCTYPE html>
<html>
    <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>Python扒取网络图片</title>
    <meta name="description" content="  就像一个黑客，随意扒取别人的资源为己用，想想就知道是一件多么酷的事儿，好像全世界的图片都是我的一样。">

    <link rel="stylesheet" href="/css/main.css">
    <link rel="canonical" href="https://huailiang.github.io/blog/2018/urlib/">
    <link rel="alternate" type="application/rss+xml" title="Huailiang Blog" href="https://huailiang.github.io/feed.xml" />
  </head>

  <body>
    <main>
      <header class="site-header">
  <div class="container">
    <h1><a href="/">Hom<span>e</span></a></h1>

    <button type="button" class="sliding-panel-button">
      <span></span>
      <span></span>
      <span></span>
    </button>

    <nav class="navbar sliding-panel-content">
      <ul>
        
        <li><a href="/about" title="About">About</a>
        </li>
        
        <li><a href="/blog" title="Blog">Blog</a>
        </li>
        
        <!-- <li><a href="https://github.com/huailiang/archive/master.zip" title="Download">Download</a></li> -->
        <li><a href="/feed.xml" target="_blank"><i class="icon icon-feed"></i></a></li>
      </ul>
    </nav>
  </div>
</header>

<div class="sliding-panel-fade-screen"></div>

      <div class="container">
        <article role="article" class="post">

  <div class="card">
    <header class="post-header">
      <h1 class="post-title">Python扒取网络图片</h1>
      <p class="post-meta">Mar 11, 2018 •
        Huailiang</p>
    </header>

    <div class="post-content">
      <blockquote>
  <p>就像一个黑客，随意扒取别人的资源为己用，想想就知道是一件多么酷的事儿，好像全世界的图片都是我的一样。</p>
</blockquote>

<p>首先安装 BeautifulSoup。</p>

<p>beautifulsoup就是一个非常强大的工具，爬虫利器。</p>

<p>beautifulSoup “美味的汤，绿色的浓汤”</p>

<p>一个灵活又方便的网页解析库，处理高效，支持多种解析器。</p>

<p>利用它就不用编写正则表达式也能方便的实现网页信息的抓取。</p>

<p>Beautiful Soup支持Python标准库中的HTML解析器,还支持一些第三方的解析器，如果我们不安装它，则 Python 会使用 Python默认的解析器，lxml 解析器更加强大，速度更快，推荐安装。</p>

<p><img src="/img/in-post/post-tf/ft24.png" alt="" /></p>

<h3 id="基本使用">基本使用</h3>
<p>标签选择器</p>

<p>在快速使用中我们添加如下代码：</p>

<pre><code class="language-py">  print(soup.title)
  print(type(soup.title))
  print(soup.head)
  print(soup.p)
</code></pre>

<p>通过这种soup.标签名 我们就可以获得这个标签的内容<br />
  这里有个问题需要注意，通过这种方式获取标签，如果文档中有多个这样的标签，返回的结果是第一个标签的内容，如上面我们通过soup.p获取p标签，而文档中有多个p标签，但是只返回了第一个p标签内容</p>

<ul>
  <li>
    <p>获取名称</p>

    <p>当我们通过soup.title.name的时候就可以获得该title标签的名称，即title</p>
  </li>
  <li>获取属性
    <pre><code class="language-py">print(soup.p.attrs['name'])
print(soup.p['name'])
</code></pre>
    <p>上面两种方式都可以获取p标签的name属性值</p>
  </li>
  <li>
    <p>获取内容</p>

    <pre><code class="language-py">print(soup.p.string)
</code></pre>
    <p>结果就可以获取第一个p标签的内容：<br />
The Dormouse’s story</p>
  </li>
  <li>
    <p>嵌套选择</p>

    <p>我们直接可以通过下面嵌套的方式获取</p>

    <pre><code class="language-py">print(soup.head.title.string)
</code></pre>
  </li>
</ul>

<p>下面代码就是展示了利用 BeautifulSoup 扒取《国家地理》里的精美图片。我们可以设置最大的链接页面 max=5. 所有扒取的图片都存在跟nationalgeographic文件夹下。</p>

<pre><code class="language-py"># coding=utf-8

import os
import shutil
import requests
from bs4 import BeautifulSoup
from urllib import urlretrieve

max=5
dest = "./nationalgeographic/"
URL = "http://www.nationalgeographic.com.cn/animals/"

"""
扒取之前，先清理干净本地目录
"""

def clear():
	if os.path.exists(dest):
		shutil.rmtree(dest)
	os.makedirs(dest)


"""
扒取下载图片
"""
def download(addr):
	# 用global关键字来进行说明该变量是全局变量
	global max

	html = requests.get(addr).text
	soup = BeautifulSoup(html,"lxml")
	print soup.title
	imgs=soup.find_all('img')
	for img in imgs:
		url=img['src']
		file=url.split('/')[-1]
		if url.startswith("http") and url.endswith("jpg"):
		# urlretrieve(url,dest+file)
			print url
			r=requests.get(url,stream=True)
			with open(dest+file,'wb') as f:
				for chunk in r.iter_content(chunk_size=128):
					f.write(chunk)
	links=soup.find_all('a')
	for link in links:
	 	url=link['href']
	 	# print url
	 	if max &gt;0 and url.startswith("http"):
 			download(url)
	 		max=max-1

if __name__=="__main__":
	clear()
	download(URL)

</code></pre>

<p>当我们使用urlretrieve下载图片的时候，发现有的图片下载不下来，使用requests.get(url,stream=True)可以比较完整的下载图片。</p>

<p><img src="/img/in-post/post-tf/tf23.png" alt="" /></p>

<p>我们也可以多进程下载，这样可以加快下载速度。</p>

<p>代码实现类似这样：</p>

<pre><code class="language-Python">
import multiprocessing as mp
import threading as td

if __name__=="__main__":
	for i,categorie in enumerate(categories):
		clear(categorie)
		logging.info(categorie)
		#使用多进程
		p=mp.Process(target=download,args=(categorie,))
		p.start()
    # p.join()
</code></pre>

<p>在使用多进程的时候，在 for 循环中调用 jion 的时候，发现并不能触发多进程，实际上只有一个进程，另一个进程可能在等待。</p>

<p>还有就是 args是一定是（）元组，当参数只有一个时候，记得加一个逗号。否则会包参数不对的 error.</p>

<p>在 Unix 平台山，当某个进程终结之后，该进程需要被父进程调用 wait,否则进程成为僵尸进程（Zombie). 所以有必要对每个 Process对象调用 join() 函数。</p>

<p>对于多进程的使用，我们强烈建议使用进程池，详情请参考<a href="http://blog.csdn.net/seetheworld518/article/details/49639651">这篇文章</a></p>


    </div>

  </div>

</article>
      </div>

      <footer class="site-footer">
  <div class="container">
    <ul class="social">
  <li><a href="https://github.com/huailiang" target="_blank"><i class="icon icon-github"></i></a></li>
  <li><a href="https://twitter.com/penghuailiang" target="_blank"><i class="icon icon-twitter"></i></a></li>
  <li><a href="https://www.facebook.com/profile.php?id=100004290725320" target="_blank"><i class="icon icon-facebook"></i></a></li>
  <li><a href="https://www.linkedin.com/in/penghuailiang/" target="_blank"><i class="icon icon-linkedin"></i></a></li>
</ul>
    <p class="txt-medium-gray">
      <small>&copy;2019 All rights reserved. Made with <a href="https://huailiang.github.io/"
          target="_blank">Huailiang</a> and ♥</small>
    </p>
  </div>
</footer>

      <a href="https://github.com/huailiang" target="_blank" class="github-corner"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#337ab7; color:#fff; position: absolute; top: 0; border: 0; right: 0;"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

      <script src="//code.jquery.com/jquery-1.11.3.min.js"></script>
      <script>
      $(document).ready(function() {
        $('.sliding-panel-button,.sliding-panel-fade-screen,.sliding-panel-close').on('click touchstart',function (e) {
          $('.sliding-panel-content,.sliding-panel-fade-screen').toggleClass('is-visible');
          e.preventDefault();
        });
      });
      </script>
    </main>
  </body>
</html>
